procdf<-data.frame(supplier,description)
procdf$description<-as.character(procdf$description)
for (ctr in 1:numSuppliers){
# get a list of rows from original df that has matching suppliers
idx<-which(df$Supplier.ID==supplier[ctr])
# figure out index of rows in original file with this supplier
l<-length(idx)
workingText<-c("")
# for each supplier, concatenate text of interest into working text
for (j in 1:l){
rowidx<-idx[j]
workingText<-paste0(workingText,df[rowidx,3])
}
procdf[ctr,2]<-
vapply(lapply(strsplit(workingText, " "), unique),
paste, character(1L), collapse = " ")
}
corpus<-Corpus(VectorSource(procdf$description))
cleancorpus<-tm_map(corpus,removeWords,stopwords("english"))
cleancorpus<-tm_map(cleancorpus,stemDocument)
dtm<-DocumentTermMatrix(cleancorpus)
dtm_tfxidf<-weightTfIdf(dtm)
m<-as.matrix(dtm_tfxidf)
rownames(m) <- 1:nrow(m)
setwd("C:/Users/koushikk/repos/XeevaIDM/R1.3")
##################################################################################
##### 1 - INITIALIZE SCRIPT PARAMETERS
##################################################################################
## Load the needed libraries and functions
library(gdata)
library(tm)
library(SnowballC)
## Set script parameters
set.seed(12345) # for repeatability of random numbers
#datafileName<-"c:\\idm\\Step4ReducedNatGeoFileAP1.xlsx" # source file
datafileName<-"c:\\idm\\Step4ReducedNatGeoFileAP1.xlsx" # source file
df<-read.xls(datafileName,sheet=1,header=TRUE)
numSuppliers<-length(unique(df$Supplier.ID))
## Create blank dataframe
supplier<-sort(unique(df$Supplier.ID),decreasing=FALSE) # supplierIDs in asc order
description<-c(rep("",numSuppliers))
procdf<-data.frame(supplier,description)
procdf$description<-as.character(procdf$description)
for (ctr in 1:numSuppliers){
# Loop is running for supplier referenced by supplier[ctr]
# Retrieve rows from original dataframe that have
# suppliers matching with supplier[ctr]
idx<-which(df$Supplier.ID==supplier[ctr])
# how many rows have this supplier?
l<-length(idx)
# initialize working variable
workingText<-c("")
# Loop through the matching records and concatenate
# text of interest into workingText variable
for (j in 1:l){
# get row reference
rowidx<-idx[j]
# retrieve and concatenate text
workingText<-paste0(workingText,df[rowidx,3])
}
# perform stemming on the text
workingText<-wordStem(workingText,language='porter')
# remove duplicate words from the text post stemming and assign
# back into procdf
procdf[ctr,2]<-
vapply(lapply(strsplit(workingText, " "), unique),
paste, character(1L), collapse = " ")
}
corpus<-Corpus(VectorSource(procdf$description))
cleancorpus<-tm_map(corpus,removeWords,stopwords("english"))
?wordcloud
install.packages(wordcloud)
install.packages("wordcloud")
library(wordcloud)
?wordcloud
wordcloud(cleancorpus,max.words=100,scale=c(5,0.5))
cleancorpus<-tm_map(cleancorpus,removeNumbers)
cleancorpus<-tm_map(cleancorpus,removePunctuation)
wordcloud(cleancorpus,max.words=100,scale=c(5,0.5))
tdm<-TermDocumentMatrix(cleanCorpus)
tdm<-TermDocumentMatrix(cleancorpus)
m<-as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
View(d)
11813*5046
head(tdm$Terms)
head(tdm[[6]][1])
?tm
?writeCorpus
testdf<-data.frame(Description=unlist(sapply(cleancorpus,`[`])),stringAsFactors=F)
testdf<-data.frame(Description=unlist(sapply(cleancorpus,`[`)),stringAsFactors=F)
View(testdf)
##################################################################################
##### 1 - INITIALIZE SCRIPT PARAMETERS
##################################################################################
## Load the needed libraries and functions
library(gdata)
library(tm)
library(SnowballC)
library(wordcloud)
## Set script parameters
set.seed(12345) # for repeatability of random numbers
#datafileName<-"c:\\idm\\Step4ReducedNatGeoFileAP1.xlsx" # source file
datafileName<-"c:\\idm\\Step4ReducedNatGeoFileAPminusModelA.xlsx" # source file
## Read file into R
df<-read.xls(datafileName,sheet=1,header=TRUE)
numSuppliers<-length(unique(df$Supplier.ID))
## Create blank dataframe
supplier<-sort(unique(df$Supplier.ID),decreasing=FALSE) # supplierIDs in asc order
description<-c(rep("",numSuppliers))
procdf<-data.frame(supplier,description)
procdf$description<-as.character(procdf$description)
for (ctr in 1:numSuppliers){
# Loop is running for supplier referenced by supplier[ctr]
# Retrieve rows from original dataframe that have
# suppliers matching with supplier[ctr]
idx<-which(df$Supplier.ID==supplier[ctr])
# how many rows have this supplier?
l<-length(idx)
# initialize working variable
workingText<-c("")
# Loop through the matching records and concatenate
# text of interest into workingText variable
for (j in 1:l){
# get row reference
rowidx<-idx[j]
# retrieve and concatenate text
workingText<-paste0(workingText,df[rowidx,3])
}
# perform stemming on the text
workingText<-wordStem(workingText,language='porter')
# remove duplicate words from the text post stemming and assign
# back into procdf
procdf[ctr,2]<-
vapply(lapply(strsplit(workingText, " "), unique),
paste, character(1L), collapse = " ")
}
corpus<-Corpus(VectorSource(procdf$description))
cleancorpus<-tm_map(corpus,removeWords,stopwords("english"))
cleancorpus<-tm_map(cleancorpus,removeNumbers)
cleancorpus<-tm_map(cleancorpus,removePunctuation)
tdm<-TermDocumentMatrix(cleanCorpus)
workingm<-as.matrix(tdm)
v <- sort(rowSums(workingm),decreasing=TRUE)
termsFreqdf <- data.frame(word = names(v),freq=v)
tdm<-TermDocumentMatrix(cleancorpus)
workingm<-as.matrix(tdm)
v <- sort(rowSums(workingm),decreasing=TRUE)
termsFreqdf <- data.frame(word = names(v),freq=v)
View(termsFreqdf)
##################################################################################
##### 1 - INITIALIZE SCRIPT PARAMETERS
##################################################################################
## Load the needed libraries and functions
library(gdata)
library(tm)
library(SnowballC)
set.seed(12345) # for repeatability of random numbers
#datafileName<-"c:\\idm\\Step4ReducedNatGeoFileAP1.xlsx" # source file
datafileName<-"c:\\idm\\Step4ReducedNatGeoFileAPminusModelA.xlsx" # source file
df<-read.xls(datafileName,sheet=1,header=TRUE)
numSuppliers<-length(unique(df$Supplier.ID))
supplier<-sort(unique(df$Supplier.ID),decreasing=FALSE) # supplierIDs in asc order
description<-c(rep("",numSuppliers))
procdf<-data.frame(supplier,description)
procdf$description<-as.character(procdf$description)
View(procdf)
for (ctr in 1:numSuppliers){
# Loop is running for supplier referenced by supplier[ctr]
# Retrieve rows from original dataframe that have
# suppliers matching with supplier[ctr]
idx<-which(df$Supplier.ID==supplier[ctr])
# how many rows have this supplier?
l<-length(idx)
# initialize working variable
workingText<-c("")
# Loop through the matching records and concatenate
# text of interest into workingText variable
for (j in 1:l){
# get row reference
rowidx<-idx[j]
# retrieve and concatenate text
workingText<-paste0(workingText,df[rowidx,3])
}
# perform stemming on the text
workingText<-wordStem(workingText,language='porter')
# remove duplicate words from the text post stemming and assign
# back into procdf
procdf[ctr,2]<-
vapply(lapply(strsplit(workingText, " "), unique),
paste, character(1L), collapse = " ")
}
View(procdf)
library(gdata)
library(tm)
library(SnowballC)
## Set script parameters
set.seed(12345) # for repeatability of random numbers
#datafileName<-"c:\\idm\\Step4ReducedNatGeoFileAP1.xlsx" # source file
datafileName<-"c:\\idm\\Step4ReducedNatGeoFileAPminusModelA.xlsx" # source file
##################################################################################
##### 2 - READ DATA FILE INTO R AND PERFORM DATA PREPROCESSING
##################################################################################
## Read file into R
df<-read.xls(datafileName,sheet=1,header=TRUE)
numSuppliers<-length(unique(df$Supplier.ID))
## Create blank dataframe
supplier<-sort(unique(df$Supplier.ID),decreasing=FALSE) # supplierIDs in asc order
description<-c(rep("",numSuppliers))
procdf<-data.frame(supplier,description)
procdf$description<-as.character(procdf$description)
## populate dataframe with text from each supplier from original file
## Loop below operates once for each unique supplier referenced in both
## supplier and procdf variables
for (ctr in 1:numSuppliers){
# Loop is running for supplier referenced by supplier[ctr]
# Retrieve rows from original dataframe that have
# suppliers matching with supplier[ctr]
idx<-which(df$Supplier.ID==supplier[ctr])
# how many rows have this supplier?
l<-length(idx)
# initialize working variable
workingText<-c("")
# Loop through the matching records and concatenate
# text of interest into workingText variable
for (j in 1:l){
# get row reference
rowidx<-idx[j]
# retrieve and concatenate text
workingText<-paste0(workingText,df[rowidx,3])
}
# perform stemming on the text
workingText<-wordStem(workingText,language='porter')
# remove duplicate words from the text post stemming and assign
# back into procdf
procdf[ctr,2]<-
vapply(lapply(strsplit(workingText, " "), unique),
paste, character(1L), collapse = " ")
}
View(procdf)
corpus<-Corpus(VectorSource(procdf$description))
cleancorpus<-tm_map(corpus,removeWords,stopwords("english"))
cleancorpus<-tm_map(cleancorpus,removeNumbers)
cleancorpus<-tm_map(cleancorpus,removePunctuation)
tdm<-TermDocumentMatrix(cleancorpus)
workingm<-as.matrix(tdm)
v <- sort(rowSums(workingm),decreasing=TRUE)
termsFreqdf <- data.frame(word = names(v),freq=v)
View(termsFreqdf)
terms<-tdm[[6]][1]
terms<-as.character(tdm[[6]][1])
termofInterest<-c("royalties")
termIdx<-which(terms==termofInterest)
?subset
subset(workingm,rownames(workingm)==c("royalties"))
container<-subset(workingm,rownames(workingm)==c("royalties"))
which(container>0)
idx<-which(container>0)
supplier(idx)
supplier[idx]
termofInterest<-c("royalties")
container<-subset(workingm,rownames(workingm)==termsofInterest)
docsWithTerm<-which(container>0)
qualifyingSuppliers<-supplier[docsWithTerm]
container<-subset(workingm,rownames(workingm)==termofInterest)
docsWithTerm<-which(container>0)
qualifyingSuppliers<-supplier[docsWithTerm]
?write.csv
write.csv(qualifyingSuppliers,outputFile)
outputFile<-"c:\\idm\term.csv"
write.csv(qualifyingSuppliers,outputFile)
outputFile<-"c:\\idm\\term.csv"
write.csv(qualifyingSuppliers,outputFile)
##################################################################################
##### 1 - INITIALIZE SCRIPT PARAMETERS
##################################################################################
## Load the needed libraries and functions
library(gdata)
library(tm)
## Set script parameters
set.seed(12345) # for repeatability of random numbers
#datafileName<-"c:\\idm\\Step4ReducedNatGeoFileAP1.xlsx" # source file
datafileName<-"c:\\idm\\Step4ReducedNatGeoFileAPminusModelA.xlsx" # source file
outputFile<-"c:\\idm\\term.csv"
##################################################################################
##### 2 - READ DATA FILE INTO R AND PERFORM DATA PREPROCESSING
##################################################################################
## Read file into R
df<-read.xls(datafileName,sheet=1,header=TRUE)
numSuppliers<-length(unique(df$Supplier.ID))
## Create blank dataframe
supplier<-sort(unique(df$Supplier.ID),decreasing=FALSE) # supplierIDs in asc order
description<-c(rep("",numSuppliers))
procdf<-data.frame(supplier,description)
procdf$description<-as.character(procdf$description)
## populate dataframe with text from each supplier from original file
## Loop below operates once for each unique supplier referenced in both
## supplier and procdf variables
for (ctr in 1:numSuppliers){
# Loop is running for supplier referenced by supplier[ctr]
# Retrieve rows from original dataframe that have
# suppliers matching with supplier[ctr]
idx<-which(df$Supplier.ID==supplier[ctr])
# how many rows have this supplier?
l<-length(idx)
# initialize working variable
workingText<-c("")
# Loop through the matching records and concatenate
# text of interest into workingText variable
for (j in 1:l){
# get row reference
rowidx<-idx[j]
# retrieve and concatenate text
workingText<-paste0(workingText,df[rowidx,3])
}
# perform stemming on the text
workingText<-wordStem(workingText,language='porter')
# remove duplicate words from the text post stemming and assign
# back into procdf
procdf[ctr,2]<-
vapply(lapply(strsplit(workingText, " "), unique),
paste, character(1L), collapse = " ")
}
##################################################################################
##### 3 - PREPARE CORPUS FOR PROCESSING
##################################################################################
## Create corpus object and remove english stop words
corpus<-Corpus(VectorSource(procdf$description))
cleancorpus<-tm_map(corpus,removeWords,stopwords("english"))
cleancorpus<-tm_map(cleancorpus,removeNumbers)
cleancorpus<-tm_map(cleancorpus,removePunctuation)
##################################################################################
##### 4 - GET TO TERMS OF INTEREST AND CORRESPONDING SUPPLIERS
##################################################################################
tdm<-TermDocumentMatrix(cleancorpus)
workingm<-as.matrix(tdm)
v <- sort(rowSums(workingm),decreasing=TRUE)
termsFreqdf <- data.frame(word = names(v),freq=v)
View(termsFreqdf)
write.csv(procdf,"c:\\idm\\SupplierRecords.csv")
termofInterest<-c("taxable")
container<-subset(workingm,rownames(workingm)==termofInterest)
docsWithTerm<-which(container>0)
qualifyingSuppliers<-supplier[docsWithTerm]
write.csv(qualifyingSuppliers,outputFile)
termofInterest<-c("photo")
container<-subset(workingm,rownames(workingm)==termofInterest)
docsWithTerm<-which(container>0)
qualifyingSuppliers<-supplier[docsWithTerm]
write.csv(qualifyingSuppliers,outputFile)
termofInterest<-c("royalties")
container<-subset(workingm,rownames(workingm)==termofInterest)
docsWithTerm<-which(container>0)
qualifyingSuppliers<-supplier[docsWithTerm]
write.csv(qualifyingSuppliers,outputFile)
termofInterest<-c("media")
container<-subset(workingm,rownames(workingm)==termofInterest)
docsWithTerm<-which(container>0)
qualifyingSuppliers<-supplier[docsWithTerm]
write.csv(qualifyingSuppliers,outputFile)
termofInterest<-c("rental")
container<-subset(workingm,rownames(workingm)==termofInterest)
docsWithTerm<-which(container>0)
qualifyingSuppliers<-supplier[docsWithTerm]
write.csv(qualifyingSuppliers,outputFile)
#write.csv(procdf,"c:\\idm\\SupplierRecords.csv")
termofInterest<-c("rental")
container<-subset(workingm,rownames(workingm)==termofInterest)
docsWithTerm<-which(container>0)
qualifyingSuppliers<-supplier[docsWithTerm]
write.csv(qualifyingSuppliers,outputFile)
#write.csv(procdf,"c:\\idm\\SupplierRecords.csv")
termofInterest<-c("digital")
container<-subset(workingm,rownames(workingm)==termofInterest)
docsWithTerm<-which(container>0)
qualifyingSuppliers<-supplier[docsWithTerm]
write.csv(qualifyingSuppliers,outputFile)
##################################################################################
##### 1 - INITIALIZE SCRIPT PARAMETERS
##################################################################################
## Load the needed libraries and functions
library(gdata)
library(tm)
## Set script parameters
set.seed(12345) # for repeatability of random numbers
#datafileName<-"c:\\idm\\Step4ReducedNatGeoFileAP1.xlsx" # source file
datafileName<-"c:\\idm\Step4ReducedNatGeoFileAPminusModelAandB1.xlsx" # source file
outputFile<-"c:\\idm\\term.csv"
##################################################################################
##### 2 - READ DATA FILE INTO R AND PERFORM DATA PREPROCESSING
##################################################################################
## Read file into R
df<-read.xls(datafileName,sheet=1,header=TRUE)
numSuppliers<-length(unique(df$Supplier.ID))
## Create blank dataframe
supplier<-sort(unique(df$Supplier.ID),decreasing=FALSE) # supplierIDs in asc order
description<-c(rep("",numSuppliers))
procdf<-data.frame(supplier,description)
procdf$description<-as.character(procdf$description)
## populate dataframe with text from each supplier from original file
## Loop below operates once for each unique supplier referenced in both
## supplier and procdf variables
for (ctr in 1:numSuppliers){
# Loop is running for supplier referenced by supplier[ctr]
# Retrieve rows from original dataframe that have
# suppliers matching with supplier[ctr]
idx<-which(df$Supplier.ID==supplier[ctr])
# how many rows have this supplier?
l<-length(idx)
# initialize working variable
workingText<-c("")
# Loop through the matching records and concatenate
# text of interest into workingText variable
for (j in 1:l){
# get row reference
rowidx<-idx[j]
# retrieve and concatenate text
workingText<-paste0(workingText,df[rowidx,4])
}
# perform stemming on the text
workingText<-wordStem(workingText,language='porter')
# remove duplicate words from the text post stemming and assign
# back into procdf
procdf[ctr,2]<-
vapply(lapply(strsplit(workingText, " "), unique),
paste, character(1L), collapse = " ")
}
##################################################################################
##### 3 - PREPARE CORPUS FOR PROCESSING
##################################################################################
## Create corpus object and remove english stop words
corpus<-Corpus(VectorSource(procdf$description))
cleancorpus<-tm_map(corpus,removeWords,stopwords("english"))
cleancorpus<-tm_map(cleancorpus,removeNumbers)
cleancorpus<-tm_map(cleancorpus,removePunctuation)
##################################################################################
##### 4 - GET TO TERMS OF INTEREST AND CORRESPONDING SUPPLIERS
##################################################################################
tdm<-TermDocumentMatrix(cleancorpus)
workingm<-as.matrix(tdm)
v <- sort(rowSums(workingm),decreasing=TRUE)
termsFreqdf <- data.frame(word = names(v),freq=v)
terms<-as.character(tdm[[6]][1])
termofInterest<-c("digital")
container<-subset(workingm,rownames(workingm)==termofInterest)
docsWithTerm<-which(container>0)
qualifyingSuppliers<-supplier[docsWithTerm]
#write.csv(qualifyingSuppliers,outputFile)
#write.csv(procdf,"c:\\idm\\SupplierRecords.csv")
##################################################################################
##### 1 - INITIALIZE SCRIPT PARAMETERS
##################################################################################
## Load the needed libraries and functions
library(gdata)
library(tm)
## Set script parameters
set.seed(12345) # for repeatability of random numbers
#datafileName<-"c:\\idm\\Step4ReducedNatGeoFileAP1.xlsx" # source file
datafileName<-"c:\\idm\\Step4ReducedNatGeoFileAPminusModelAandB1.xlsx" # source file
outputFile<-"c:\\idm\\term.csv"
##################################################################################
##### 2 - READ DATA FILE INTO R AND PERFORM DATA PREPROCESSING
##################################################################################
## Read file into R
df<-read.xls(datafileName,sheet=1,header=TRUE)
numSuppliers<-length(unique(df$Supplier.ID))
## Create blank dataframe
supplier<-sort(unique(df$Supplier.ID),decreasing=FALSE) # supplierIDs in asc order
description<-c(rep("",numSuppliers))
procdf<-data.frame(supplier,description)
procdf$description<-as.character(procdf$description)
## populate dataframe with text from each supplier from original file
## Loop below operates once for each unique supplier referenced in both
## supplier and procdf variables
for (ctr in 1:numSuppliers){
# Loop is running for supplier referenced by supplier[ctr]
# Retrieve rows from original dataframe that have
# suppliers matching with supplier[ctr]
idx<-which(df$Supplier.ID==supplier[ctr])
# how many rows have this supplier?
l<-length(idx)
# initialize working variable
workingText<-c("")
# Loop through the matching records and concatenate
# text of interest into workingText variable
for (j in 1:l){
# get row reference
rowidx<-idx[j]
# retrieve and concatenate text
workingText<-paste0(workingText,df[rowidx,4])
}
# perform stemming on the text
workingText<-wordStem(workingText,language='porter')
# remove duplicate words from the text post stemming and assign
# back into procdf
procdf[ctr,2]<-
vapply(lapply(strsplit(workingText, " "), unique),
paste, character(1L), collapse = " ")
}
View(procdf)
corpus<-Corpus(VectorSource(procdf$description))
cleancorpus<-tm_map(corpus,removeWords,stopwords("english"))
cleancorpus<-tm_map(cleancorpus,removeNumbers)
cleancorpus<-tm_map(cleancorpus,removePunctuation)
tdm<-TermDocumentMatrix(cleancorpus)
workingm<-as.matrix(tdm)
v <- sort(rowSums(workingm),decreasing=TRUE)
termsFreqdf <- data.frame(word = names(v),freq=v)
View(termsFreqdf)
View(procdf)
write.csv(procdf,"c:\\idm\\procdf.csv")
